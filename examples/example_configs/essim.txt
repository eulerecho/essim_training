{

# general inputs

'env'               :   'mjrl_essim-v0',
'algorithm'         :   'PPO',
'seed'              :   123,
'sample_mode'       :   'samples',
'rl_num_samples'    :   10000,
'rl_num_iter'       :   1500,
'num_cpu'           :   12,
'save_freq'         :   50,
'eval_rollouts'     :   None,
'exp_notes'         :   'Example config for training policy with NPG on the mjrl essim task.',

# RL parameters (all params related to PG, value function, DAPG etc.)

'policy_size'       :   (32, 32),
'init_log_std'      :   -0.5,
'vf_hidden_size'    :   (128, 128),
'vf_batch_size'     :   64,
'vf_epochs'         :   2,
'vf_learn_rate'     :   1e-3,
'rl_step_size'      :   0.1,
'rl_gamma'          :   0.995,
'rl_gae'            :   0.97,

# Algorithm hyperparameters : if alg requires additional params, can be specified here (or defaults will be used)

'alg_hyper_params'  :   dict(),

}
